{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis Demo\n",
    "\n",
    "This notebook demonstrates the usage of the TimeSeriesAnalyzer class for analyzing time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import lark\n",
    "from evaluator import EvaluateExpression\n",
    "from time_series_analyzer import TimeSeriesAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time_series_analyzer import TimeSeriesAnalyzer\n",
    "\n",
    "file_path = \"events.arrow\"\n",
    "time_col = \"time\"\n",
    "trajectory_col = \"user_id\"\n",
    "analyzer = TimeSeriesAnalyzer(file_path, time_col, trajectory_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeSeries purchase: 37346 rows>\n",
       "              id      time  purchase\n",
       "0          59177    775598         0\n",
       "1         230337    410149         0\n",
       "2         307700   1029889         0\n",
       "3         307700   1029996         1\n",
       "4         307700   1031539         1\n",
       "...          ...       ...       ...\n",
       "37341  257772564  13597486         0\n",
       "37342  257772564  13597555         1\n",
       "37343  257772564  13597673         1\n",
       "37344  257781820  13600052         0\n",
       "37345  257784860  13601742         0\n",
       "\n",
       "[37346 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "analyzer.query(\"exists {purchase} before #now at every {purchase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "Total events: 2,206,675\n",
      "Unique trajectories: 407,264\n",
      "\n",
      "TRAIN split:\n",
      "Total events: 1,550,857\n",
      "Unique trajectories: 285,085\n",
      "% of original events: 70.28%\n",
      "% of original trajectories: 70.00%\n",
      "\n",
      "VAL split:\n",
      "Total events: 325,579\n",
      "Unique trajectories: 61,090\n",
      "% of original events: 14.75%\n",
      "% of original trajectories: 15.00%\n",
      "\n",
      "TEST split:\n",
      "Total events: 330,239\n",
      "Unique trajectories: 61,089\n",
      "% of original events: 14.97%\n",
      "% of original trajectories: 15.00%\n",
      "\n",
      "Query results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 26105 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: 5542 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 5699 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#print original dataset stats\n",
    "print(\"Original dataset:\")\n",
    "print(f\"Total events: {analyzer.get_total_events():,}\")\n",
    "print(f\"Unique trajectories: {analyzer.get_unique_trajectories():,}\")\n",
    "\n",
    "#create train/val/test splits\n",
    "splits = analyzer.split(train=0.7, val=0.15, test=0.15)\n",
    "\n",
    "#print stats for each split\n",
    "for name, split_analyzer in splits.items():\n",
    "    print(f\"\\n{name.upper()} split:\")\n",
    "    print(f\"Total events: {split_analyzer.get_total_events():,}\")\n",
    "    print(f\"Unique trajectories: {split_analyzer.get_unique_trajectories():,}\")\n",
    "    print(f\"% of original events: {split_analyzer.get_total_events() / analyzer.get_total_events() * 100:.2f}%\")\n",
    "    print(f\"% of original trajectories: {split_analyzer.get_unique_trajectories() / analyzer.get_unique_trajectories() * 100:.2f}%\")\n",
    "\n",
    "#test a query on each split\n",
    "query = \"exists {purchase} before #now at every {purchase}\"\n",
    "print(\"\\nQuery results:\")\n",
    "for name, split_analyzer in splits.items():\n",
    "    result = split_analyzer.query(query)\n",
    "    print(f\"{name}: {len(result) if hasattr(result, '__len__') else 'N/A'} results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
